{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecoyComp: Dataset Comparison Executive Summary\n",
    "\n",
    "**Purpose**: Quick comparison of molecular benchmark datasets for virtual screening\n",
    "\n",
    "**Datasets Analyzed**: LIT-PCBA, DUDE-Z, DEKOIS2, MUV, D-COID\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have generated the dataset summaries:\n",
    "\n",
    "```bash\n",
    "# Generate file-based dataset summaries\n",
    "python analyse_datasets.py --roots LIT-PCBA DUDE-Z DEKOIS2 D-COID --include-muv --outdir results\n",
    "\n",
    "# Generate visualizations (optional, can be done in notebook)\n",
    "python metrics.py --smiles-dir results/smiles --outdir results --summary-csv results/dataset_unique_summary_split.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import functions from metrics.py\n",
    "from metrics import COLOR_ACTIVE, COLOR_INACTIVE, violin_plot, compliance_bar_from_summary\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Configuration\n",
    "RESULTS_DIR = Path('results')\n",
    "SMILES_DIR = RESULTS_DIR / 'smiles'\n",
    "OUTPUT_DIR = Path('notebook_figures')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dataset colors (consistent throughout notebook)\n",
    "DATASET_COLORS = {\n",
    "    'LIT-PCBA': '#1f77b4',\n",
    "    'DUDE-Z': '#ff7f0e',\n",
    "    'DEKOIS2': '#2ca02c',\n",
    "    'MUV': '#d62728',\n",
    "    'D-COID': '#9467bd'\n",
    "}\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed summaries\n",
    "summary_file = RESULTS_DIR / 'dataset_unique_summary.csv'\n",
    "split_summary_file = RESULTS_DIR / 'dataset_unique_summary_split.csv'\n",
    "\n",
    "if not summary_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Summary file not found: {summary_file}\\n\"\n",
    "        \"Please run: python analyse_datasets.py --roots LIT-PCBA DUDE-Z DEKOIS2 D-COID --include-muv --outdir results\"\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "df_summary = pd.read_csv(summary_file)\n",
    "df_split = pd.read_csv(split_summary_file) if split_summary_file.exists() else None\n",
    "\n",
    "print(f\"‚úì Loaded summary data:\")\n",
    "print(f\"  - Overall summary: {df_summary.shape}\")\n",
    "if df_split is not None:\n",
    "    print(f\"  - Split summary: {df_split.shape}\")\n",
    "\n",
    "# Display available datasets\n",
    "datasets = df_summary['Dataset'].unique() if 'Dataset' in df_summary.columns else []\n",
    "print(f\"\\n‚úì Datasets found: {', '.join(datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Overview: Dataset Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create comprehensive comparison table\ndef create_comparison_table(df_summary, df_split):\n    \"\"\"Create a summary comparison table for all datasets.\"\"\"\n    \n    comparison = []\n    \n    for dataset in df_summary['Dataset'].unique():\n        # Get overall stats\n        overall = df_summary[df_summary['Dataset'] == dataset].iloc[0]\n        \n        # Get actives and inactives counts from overall summary\n        n_actives = int(overall.get('NumberActivesUnique', 0))\n        n_inactives = int(overall.get('NumberInactivesUnique', 0))\n        total_mols = overall['NumberLigandsUnique']\n        \n        # Calculate quality score (100 - percentage of problematic molecules)\n        invalid_pct = (overall.get('NumberInvalidSMILES', 0) / total_mols * 100) if total_mols > 0 else 0\n        quality_score = 100 - invalid_pct\n        \n        # Drug-likeness\n        lipinski = overall.get('LipinskiComplianceRate', 0) * 100\n        veber = overall.get('VeberComplianceRate', 0) * 100\n        \n        comparison.append({\n            'Dataset': dataset,\n            'Total Molecules': f\"{int(total_mols):,}\",\n            'Actives': f\"{n_actives:,}\",\n            'Decoys/Inactives': f\"{n_inactives:,}\",\n            'Active:Decoy Ratio': f\"1:{n_inactives/n_actives:.1f}\" if n_actives > 0 else 'N/A',\n            'Quality Score': f\"{quality_score:.1f}%\",\n            'Lipinski Compliant': f\"{lipinski:.1f}%\",\n            'Veber Compliant': f\"{veber:.1f}%\"\n        })\n    \n    return pd.DataFrame(comparison)\n\n# Create and display comparison table\ncomparison_df = create_comparison_table(df_summary, df_split)\n\n# Style the table\nstyled_table = comparison_df.style.set_properties(**{\n    'text-align': 'left',\n    'font-size': '11pt'\n}).set_table_styles([{\n    'selector': 'th',\n    'props': [('font-size', '12pt'), ('text-align', 'center'), ('font-weight', 'bold')]\n}])\n\ndisplay(styled_table)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bar chart: Total molecules and actives/decoys breakdown\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Total molecules\ndatasets = df_summary['Dataset'].values\ntotal_mols = df_summary['NumberLigandsUnique'].values\ncolors = [DATASET_COLORS.get(ds, 'gray') for ds in datasets]\n\nax1.bar(datasets, total_mols, color=colors, alpha=0.7)\nax1.set_ylabel('Number of Unique Molecules')\nax1.set_title('Dataset Sizes', fontweight='bold', fontsize=12)\nax1.tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor i, (ds, val) in enumerate(zip(datasets, total_mols)):\n    ax1.text(i, val, f'{int(val):,}', ha='center', va='bottom', fontsize=9)\n\n# Actives vs Decoys breakdown\nactives_counts = df_summary['NumberActivesUnique'].values\ndecoys_counts = df_summary['NumberInactivesUnique'].values\n\nx = np.arange(len(datasets))\nwidth = 0.35\n\nax2.bar(x - width/2, actives_counts, width, label='Actives', color=COLOR_ACTIVE, alpha=0.7)\nax2.bar(x + width/2, decoys_counts, width, label='Decoys/Inactives', color=COLOR_INACTIVE, alpha=0.7)\n\nax2.set_ylabel('Number of Molecules')\nax2.set_title('Active vs Decoy Distribution', fontweight='bold', fontsize=12)\nax2.set_xticks(x)\nax2.set_xticklabels(datasets, rotation=45, ha='right')\nax2.legend()\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'dataset_sizes.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Dataset size comparison complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Chemical Property Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or compute molecular descriptors\n",
    "descriptors_file = RESULTS_DIR / 'ligand_descriptors.csv'\n",
    "\n",
    "if descriptors_file.exists():\n",
    "    print(f\"Loading descriptors from {descriptors_file}...\")\n",
    "    df_desc = pd.read_csv(descriptors_file)\n",
    "    print(f\"‚úì Loaded {len(df_desc):,} molecular descriptors\")\n",
    "else:\n",
    "    print(\"‚ö† Descriptor file not found. Run metrics.py first or compute descriptors below.\")\n",
    "    print(\"  python metrics.py --smiles-dir results/smiles --outdir results\")\n",
    "    df_desc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plots for key descriptors\n",
    "if df_desc is not None:\n",
    "    print(\"Generating molecular property distribution plots...\")\n",
    "    \n",
    "    # Use existing violin_plot function from metrics.py\n",
    "    violin_plot(df_desc, \"mw\", \"Molecular Weight (Da)\", \n",
    "                \"Molecular Weight Distribution\", OUTPUT_DIR / \"violin_mw.png\")\n",
    "    \n",
    "    violin_plot(df_desc, \"tpsa\", \"TPSA (≈≤)\", \n",
    "                \"Topological Polar Surface Area\", OUTPUT_DIR / \"violin_tpsa.png\")\n",
    "    \n",
    "    violin_plot(df_desc, \"rotbonds\", \"Rotatable Bonds\", \n",
    "                \"Rotatable Bonds Distribution\", OUTPUT_DIR / \"violin_rotbonds.png\")\n",
    "    \n",
    "    print(\"‚úì Violin plots saved to\", OUTPUT_DIR)\n",
    "    \n",
    "    # Display the MW plot inline\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=OUTPUT_DIR / \"violin_mw.png\"))\n",
    "else:\n",
    "    print(\"‚ö† Skipping violin plots (descriptors not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Drug-likeness Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug-likeness compliance (Lipinski & Veber)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "datasets = df_summary['Dataset'].values\n",
    "lipinski_rates = df_summary['LipinskiComplianceRate'].values * 100\n",
    "veber_rates = df_summary['VeberComplianceRate'].values * 100\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, lipinski_rates, width, label=\"Lipinski's Rule of Five\", \n",
    "               color='#3498db', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, veber_rates, width, label=\"Veber's Rule\", \n",
    "               color='#e74c3c', alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_ylabel('Compliance Rate (%)', fontsize=11)\n",
    "ax.set_title('Drug-likeness Rule Compliance', fontweight='bold', fontsize=13)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets, rotation=45, ha='right')\n",
    "ax.set_ylim(0, 105)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'druglikeness_compliance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Drug-likeness compliance chart complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Quality Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create quality metrics matrix\ndef create_quality_matrix(df_summary):\n    \"\"\"Create a quality assessment matrix.\"\"\"\n    quality_data = []\n    \n    for ds in df_summary['Dataset'].values:\n        row = df_summary[df_summary['Dataset'] == ds].iloc[0]\n        total = row['NumberLigandsUnique']\n        \n        # Calculate percentages\n        invalid_pct = (row.get('NumberInvalidSMILES', 0) / total * 100) if total > 0 else 0\n        valid_pct = 100 - invalid_pct\n        lipinski_pct = row.get('LipinskiComplianceRate', 0) * 100\n        veber_pct = row.get('VeberComplianceRate', 0) * 100\n        \n        quality_data.append({\n            'Dataset': ds,\n            'Valid SMILES': valid_pct,\n            'Lipinski Compliant': lipinski_pct,\n            'Veber Compliant': veber_pct\n        })\n    \n    return pd.DataFrame(quality_data)\n\nquality_df = create_quality_matrix(df_summary)\n\n# Create heatmap\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Prepare data for heatmap (transpose so datasets are columns)\nheatmap_data = quality_df.set_index('Dataset').T\n\n# Create heatmap\nsns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='RdYlGn', \n            vmin=0, vmax=100, cbar_kws={'label': 'Percentage (%)'},\n            linewidths=0.5, ax=ax)\n\nax.set_title('Data Quality Scorecard', fontweight='bold', fontsize=13, pad=15)\nax.set_xlabel('Dataset', fontsize=11)\nax.set_ylabel('Quality Metric', fontsize=11)\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'quality_scorecard.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Quality scorecard complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Chemical Space Visualization (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization of chemical space\n",
    "if df_desc is not None:\n",
    "    print(\"Computing PCA for chemical space visualization...\")\n",
    "    \n",
    "    # Sample if too large (for performance)\n",
    "    max_samples_per_dataset = 5000\n",
    "    df_sampled = df_desc.groupby('dataset').apply(\n",
    "        lambda x: x.sample(n=min(len(x), max_samples_per_dataset), random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Using {len(df_sampled):,} molecules for PCA (sampled from {len(df_desc):,})\")\n",
    "    \n",
    "    # Prepare descriptor matrix\n",
    "    X = df_sampled[['mw', 'tpsa', 'rotbonds']].values\n",
    "    \n",
    "    # Standardize and apply PCA\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    for ds in df_sampled['dataset'].unique():\n",
    "        mask = df_sampled['dataset'] == ds\n",
    "        ax.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                  label=ds, alpha=0.4, s=10,\n",
    "                  color=DATASET_COLORS.get(ds, 'gray'))\n",
    "    \n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=11)\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=11)\n",
    "    ax.set_title('Chemical Space Distribution (PCA)', fontweight='bold', fontsize=13)\n",
    "    ax.legend(loc='best', framealpha=0.9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'chemical_space_pca.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì PCA complete (explained variance: {pca.explained_variance_ratio_.sum()*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ö† Skipping PCA (descriptors not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Auto-generate key findings\ndef generate_key_findings(df_summary, df_split):\n    \"\"\"Automatically identify and report key findings.\"\"\"\n    findings = []\n    \n    # 1. Dataset sizes\n    largest_ds = df_summary.loc[df_summary['NumberLigandsUnique'].idxmax()]\n    smallest_ds = df_summary.loc[df_summary['NumberLigandsUnique'].idxmin()]\n    \n    findings.append(\n        f\"**Dataset Size**: {largest_ds['Dataset']} is the largest with \"\n        f\"{int(largest_ds['NumberLigandsUnique']):,} unique molecules, while \"\n        f\"{smallest_ds['Dataset']} is the smallest with {int(smallest_ds['NumberLigandsUnique']):,} molecules.\"\n    )\n    \n    # 2. Drug-likeness\n    best_lipinski = df_summary.loc[df_summary['LipinskiComplianceRate'].idxmax()]\n    findings.append(\n        f\"**Drug-likeness**: {best_lipinski['Dataset']} has the highest Lipinski compliance at \"\n        f\"{best_lipinski['LipinskiComplianceRate']*100:.1f}%, making it most suitable for drug-like compound screening.\"\n    )\n    \n    # 3. Data quality\n    df_summary_copy = df_summary.copy()\n    df_summary_copy['invalid_rate'] = df_summary_copy['NumberInvalidSMILES'] / df_summary_copy['NumberLigandsUnique']\n    cleanest_ds = df_summary_copy.loc[df_summary_copy['invalid_rate'].idxmin()]\n    findings.append(\n        f\"**Data Quality**: {cleanest_ds['Dataset']} has the lowest rate of invalid SMILES \"\n        f\"({cleanest_ds['invalid_rate']*100:.3f}%), indicating high data quality.\"\n    )\n    \n    # 4. Active:Decoy ratios\n    ratios = []\n    for ds in df_summary['Dataset'].unique():\n        row = df_summary[df_summary['Dataset'] == ds].iloc[0]\n        n_actives = row['NumberActivesUnique']\n        n_inactives = row['NumberInactivesUnique']\n        if n_actives > 0:\n            ratios.append((ds, n_inactives / n_actives))\n    \n    if ratios:\n        most_balanced = min(ratios, key=lambda x: abs(x[1] - 1))\n        findings.append(\n            f\"**Balance**: {most_balanced[0]} has the most balanced active:decoy ratio \"\n            f\"(1:{most_balanced[1]:.1f}), ideal for unbiased model training.\"\n        )\n    \n    return findings\n\nfindings = generate_key_findings(df_summary, df_split)\n\nprint(\"## üìä Key Findings\\n\")\nfor i, finding in enumerate(findings, 1):\n    print(f\"{i}. {finding}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case recommendations\n",
    "recommendations = {\n",
    "    'Method Development & Testing': [\n",
    "        'Use the cleanest dataset with high-quality SMILES',\n",
    "        'Recommended: Dataset with highest data quality score'\n",
    "    ],\n",
    "    'Realistic Benchmarking': [\n",
    "        'Use literature-derived datasets for real-world relevance',\n",
    "        'Recommended: LIT-PCBA (literature sources)'\n",
    "    ],\n",
    "    'Challenging Model Evaluation': [\n",
    "        'Use datasets with matched/sophisticated decoys',\n",
    "        'Recommended: DUDE-Z (property-matched decoys)'\n",
    "    ],\n",
    "    'Drug-like Compound Screening': [\n",
    "        'Use dataset with highest Lipinski compliance',\n",
    "        f'Recommended: {df_summary.loc[df_summary[\"LipinskiComplianceRate\"].idxmax(), \"Dataset\"]}'\n",
    "    ],\n",
    "    'Structure-based Studies': [\n",
    "        'Use datasets with structural information',\n",
    "        'Recommended: D-COID (PDB-derived structures)'\n",
    "    ],\n",
    "    'Bioactivity Prediction': [\n",
    "        'Use datasets with experimental bioactivity data',\n",
    "        'Recommended: MUV (bioactivity database)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"## üéØ Use Case Recommendations\\n\")\n",
    "for use_case, details in recommendations.items():\n",
    "    print(f\"**{use_case}**\")\n",
    "    for detail in details:\n",
    "        print(f\"  ‚Ä¢ {detail}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics for molecular descriptors\n",
    "if df_desc is not None:\n",
    "    stats_summary = df_desc.groupby('dataset').agg({\n",
    "        'mw': ['mean', 'std', 'median'],\n",
    "        'tpsa': ['mean', 'std', 'median'],\n",
    "        'rotbonds': ['mean', 'std', 'median']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    stats_summary.columns = [f'{desc}_{stat}' for desc, stat in stats_summary.columns]\n",
    "    \n",
    "    print(\"## üìà Molecular Descriptor Statistics\\n\")\n",
    "    display(stats_summary)\n",
    "    \n",
    "    # Save to CSV\n",
    "    stats_summary.to_csv(OUTPUT_DIR / 'descriptor_statistics.csv')\n",
    "    print(f\"\\n‚úì Statistics saved to {OUTPUT_DIR / 'descriptor_statistics.csv'}\")\n",
    "else:\n",
    "    print(\"‚ö† Descriptor statistics not available (descriptors not loaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n",
    "\n",
    "### Summary\n",
    "\n",
    "This executive summary compared five benchmark molecular datasets for virtual screening:\n",
    "\n",
    "- **LIT-PCBA**: Literature-derived actives and inactives\n",
    "- **DUDE-Z**: Property-matched decoys for challenging evaluation\n",
    "- **DEKOIS2**: ZINC-derived decoys with diverse scaffolds\n",
    "- **MUV**: Bioactivity database with experimental data\n",
    "- **D-COID**: Structure-based dataset from PDB complexes\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Select appropriate dataset(s)** based on use case recommendations above\n",
    "2. **Consider combining datasets** for more robust validation\n",
    "3. **Validate findings** with your specific screening protocol\n",
    "4. **Consult comprehensive analysis** notebook for detailed statistics\n",
    "\n",
    "---\n",
    "\n",
    "**For detailed analysis**: See `dataset_comparison_comprehensive.ipynb` (when available)\n",
    "\n",
    "**Questions or feedback**: [Contact information]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of generated outputs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÅ OUTPUTS GENERATED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAll figures saved to: {OUTPUT_DIR.absolute()}\\n\")\n",
    "\n",
    "output_files = list(OUTPUT_DIR.glob('*.png')) + list(OUTPUT_DIR.glob('*.csv'))\n",
    "for f in sorted(output_files):\n",
    "    print(f\"  ‚úì {f.name}\")\n",
    "\n",
    "print(f\"\\nTotal files: {len(output_files)}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}